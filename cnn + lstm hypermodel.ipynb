{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "from pickle import load\n",
    "from math import ceil\n",
    "from numpy.random import choice\n",
    "from keras import Model\n",
    "from keras.applications import ResNet152V2\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Add, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions.text_processing import create_vocab_mappings\n",
    "from functions.training import data_generator\n",
    "from functions.model_evaluation import evaluate_captions, generate_caption\n",
    "from functions.testing import generate_and_evaluate_test_caption\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras_tuner import HyperParameters, Hyperband\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Dropout, Embedding, Add, LayerNormalization, GRU, Bidirectional\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.regularizers import L1, L2, L1L2\n",
    "from keras_tuner import HyperModel, HyperParameters\n",
    "\n",
    "from keras.initializers import HeUniform, Orthogonal, GlorotUniform\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 15\n",
    "FEATURE_SIZE = 2048\n",
    "EMB_DIM = 300 # can only be values 100, 200, 300\n",
    "HIDDEN_DIM = 512\n",
    "EPOCHS = 100\n",
    "DROPOUT = 0.4\n",
    "BATCH_SIZE = 512\n",
    "EVAL_BATCH_SIZE = 1024\n",
    "DIR = 'preprocessed_data/coco/'\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DIR + 'train_caption_map.pkl', 'rb') as file:\n",
    "    train_caption_map = load(file)\n",
    "    \n",
    "with open(DIR + 'train_feature_map.pkl', 'rb') as file: \n",
    "    train_feature_map = load(file)\n",
    "\n",
    "with open(DIR + 'val_caption_map.pkl', 'rb') as file:\n",
    "    val_caption_map = load(file)\n",
    "    \n",
    "with open(DIR + 'val_feature_map.pkl', 'rb') as file:\n",
    "    val_feature_map = load(file)\n",
    "\n",
    "with open(DIR + 'embedding_matrix.pkl', 'rb') as file:\n",
    "    embedding_matrix = load(file)\n",
    "    \n",
    "with open(DIR + 'vocab.pkl', 'rb') as file:\n",
    "    vocab = load(file)\n",
    "    \n",
    "train_images = list(train_caption_map.keys())\n",
    "val_images = list(val_caption_map.keys())\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "STEPS = ceil(len(train_images) * 5 / BATCH_SIZE)\n",
    "VAL_STEPS = ceil(len(val_images) * 5 / BATCH_SIZE)\n",
    "\n",
    "word_to_idx, idx_to_word = create_vocab_mappings(vocab)\n",
    "\n",
    "train_data = data_generator (train_images, train_caption_map, train_feature_map, BATCH_SIZE)\n",
    "val_data = data_generator(val_images, val_caption_map, val_feature_map, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, feature_size = 1536, seq_len= 15, vocab_size= 4096, hidden_dim= 1024, seed = 17):\n",
    "        super().__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seed = seed\n",
    "        \n",
    "    def build(self, hp):       \n",
    "        tf.random.set_seed(self.seed)\n",
    "        \n",
    "        dropout_rate = hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)\n",
    "        reg_type = hp.Choice('regularizer_type', values=['none', 'l2'])\n",
    "        reg_factor = hp.Choice('regularization_factor', values=[1e-6, 1e-4, 1e-2]) \n",
    "        use_layer_norm = hp.Boolean('use_layer_norm')\n",
    "            \n",
    "        regularizer = L2(reg_factor) if reg_type == 'l2' else None\n",
    "\n",
    "        optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop'])\n",
    "        learning_rate = hp.Choice('learning_rate', values=[1e-5, 1e-4, 1e-3, 1e-2])\n",
    "\n",
    "        # Embedding layer\n",
    "        embedding_layer = Embedding(self.vocab_size, self.embedding_matrix.shape[1], input_length=self.seq_len, trainable=False, weights=[self.embedding_matrix], name='sequence_embedding')\n",
    "\n",
    "        # Image layers\n",
    "        image_input = Input(shape=(self.feature_size), name='image_input')\n",
    "        image_dropout = Dropout(dropout_rate, name='image_dropout')(image_input)\n",
    "        x_img = Dense(self.hidden_dim, activation = 'relu', kernel_initializer= HeUniform(), kernel_regularizer=regularizer, name='image_dense')(image_dropout)    \n",
    "        if use_layer_norm:\n",
    "            x_img = LayerNormalization()(x_img) \n",
    "\n",
    "        # Sequence layers\n",
    "        caption_input = Input(shape=(self.seq_len,), name='caption_input')\n",
    "        caption_embedding = embedding_layer(caption_input)\n",
    "        caption_dropout = Dropout(dropout_rate, name='embedding_dropout')(caption_embedding)\n",
    "        \n",
    "        x_caption = LSTM(self.hidden_dim, return_sequences=True, kernel_initializer= Orthogonal(), kernel_regularizer=regularizer, recurrent_regularizer=regularizer, name='lstm_layer')(caption_dropout)\n",
    "        if use_layer_norm:\n",
    "            x_caption = LayerNormalization()(x_caption)\n",
    "\n",
    "        # Combine image and sequence\n",
    "        merging_layer = Add()([x_img, x_caption])\n",
    "        merge_dropout = Dropout(dropout_rate)(merging_layer)\n",
    "\n",
    "        # Prediction layers        \n",
    "        x_pred = Dense(self.hidden_dim, activation='relu', kernel_initializer= HeUniform(), kernel_regularizer=regularizer)(merge_dropout)\n",
    "        if use_layer_norm:\n",
    "            x_pred = LayerNormalization()(x_pred)\n",
    "        prediction_dropout = Dropout(dropout_rate)(x_pred)\n",
    "        \n",
    "        output = Dense(self.vocab_size, activation='softmax', kernel_initializer= GlorotUniform(), kernel_regularizer=regularizer)(prediction_dropout)\n",
    "        \n",
    "        decoder = Model(inputs = [image_input, caption_input] , outputs = output)       \n",
    "        \n",
    "        optimizer = Adam(learning_rate) if optimizer_choice == 'adam' else RMSprop(learning_rate)\n",
    "        decoder.compile(optimizer= optimizer, loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "        \n",
    "        return decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = MyHyperModel(\n",
    "    feature_size=FEATURE_SIZE,\n",
    "    seq_len=SEQ_LEN,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    ")\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel= hypermodel,\n",
    "    executions_per_trial = 3,\n",
    "    objective='val_loss',\n",
    "    directory = 'tuning',\n",
    "    project_name = 'lstm_decoder',\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "tuner.search(\n",
    "    train_data,\n",
    "    epochs = 1,\n",
    "    steps_per_epoch=STEPS,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=VAL_STEPS,\n",
    "    callbacks= [early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_decoders = tuner.get_best_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_decoder = best_decoders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = hypermodel.build(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
    "    TensorBoard(\n",
    "            log_dir='./logs/lstm_decoder/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            update_freq='epoch'\n",
    "        )\n",
    "    ]\n",
    "\n",
    "training = model.fit(\n",
    "    train_data,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=STEPS,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=VAL_STEPS,\n",
    "    callbacks= callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "# Plotting Loss\n",
    "axes[0].plot(training.history['loss'], marker='o', color='b', label='Training Loss')\n",
    "axes[0].plot(training.history['val_loss'], marker='o', color='r', label='Validation Loss')\n",
    "axes[0].set_title('Model Loss')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plotting Accuracy\n",
    "axes[1].plot(training.history['accuracy'], marker='s', color='g', label='Training Accuracy')\n",
    "axes[1].plot(training.history['val_accuracy'], marker='s', color='orange', label='Validation Accuracy')\n",
    "axes[1].set_title('Model Accuracy')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = choice(val_images)\n",
    "test_features = val_feature_map[test_image]\n",
    "true_captions = val_caption_map[test_image]\n",
    "\n",
    "generate_and_evaluate_test_caption('datasets/coco/val2014/', test_image, test_features, idx_to_word, model, SEQ_LEN, true_captions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training outputs \n",
    "1. ([0.6405022734089714, 0.4463027082229372, 0.29934462206575563, 0.20871405332039702], 0.4145237453375769) v1\n",
    "2. ([0.6418743284682035, 0.442693660623719, 0.29415405024196956, 0.20058639500348188], 0.4080181609786798) v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.model_evaluation import batch_generate_captions, evaluate_captions\n",
    "\n",
    "predicted_captions, true_captions = batch_generate_captions(val_images, val_feature_map, val_caption_map, idx_to_word, model, SEQ_LEN, 1024)\n",
    "evaluate_captions(predicted_captions, true_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ([0.6211531810024086, 0.410840029257982, 0.26646794915971794, 0.1811533502178472], 0.38122496568020725) batch = 64\n",
    "- ([0.5993318816719131,\n",
    "  0.3865770367462274,\n",
    "  0.24482775805037613,\n",
    "  0.16440581561248588],\n",
    " 0.3609836026638695) batch = 32\n",
    " - ([0.6344307633588684,\n",
    "  0.4343686956410259,\n",
    "  0.28711750048084483,\n",
    "  0.19787981935572438],\n",
    " 0.3971223813690533) batch = 256\n",
    "- ([0.6298820729985007,\n",
    "  0.4312138237301613,\n",
    "  0.2866155554360642,\n",
    "  0.19793620298236123],\n",
    " 0.39902906753744116) previous with more training \n",
    " - ([0.6428814404792379,\n",
    "  0.4456909514391105,\n",
    "  0.29858524736881525,\n",
    "  0.2072303796603672],\n",
    " 0.4091058296690576) batch = 256, 20 epochs, model saved\n",
    " - ([0.6428814404792379,\n",
    "  0.4456909514391105,\n",
    "  0.29858524736881525,\n",
    "  0.2072303796603672],\n",
    " 0.4091058296690576) previous model with more training \n",
    " - ([0.6390607878281732,\n",
    "  0.4406290889734613,\n",
    "  0.2962323225086467,\n",
    "  0.2063178068601112],\n",
    " 0.40974129391739644) changed hid dim to 512\n",
    " - ([0.6568510950992849,\n",
    "  0.46559990385495154,\n",
    "  0.3192417928203884,\n",
    "  0.22491635004582852],\n",
    " 0.42799321255907147) added dense layer after concat \n",
    " - ([0.6592448939264582,\n",
    "  0.4687748184498835,\n",
    "  0.3229394024298345,\n",
    "  0.22790701045314818],\n",
    " 0.43095061728517275) new cnn\n",
    " - ([0.6587324526306322,\n",
    "  0.4695537527436097,\n",
    "  0.32331068826761733,\n",
    "  0.22825250420482918],\n",
    " 0.4321113122628307) new cnn training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder.save('models/lstm_decoder_for_cnn_encoder.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
