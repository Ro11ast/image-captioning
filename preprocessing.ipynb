{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization \n",
    "from tensorflow.data import Dataset, AUTOTUNE  \n",
    "from keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from pickle import dump\n",
    "from numpy.random import choice \n",
    "\n",
    "from functions.dataset_loading import load_flicker8k_captions, load_coco_captions\n",
    "from functions.text_processing import custom_standardization, vectorize_captions, create_vocab_mappings\n",
    "from functions.dataset_loading import create_embedding_matrix\n",
    "from functions.image_processing import batch_extract_features\n",
    "from functions.model_evaluation import decode_caption\n",
    "\n",
    "from keras.mixed_precision import set_global_policy\n",
    "set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 20\n",
    "EMBED_DIM = 300\n",
    "MAX_TOKENS = 4096\n",
    "FLICKER = 'preprocessed_data/flicker8k/'\n",
    "COCO = 'preprocessed_data/coco/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total flicker images:  8091\n",
      "Total flicker captions: 40455\n"
     ]
    }
   ],
   "source": [
    "flicker_caption_map, flicker_total_captions = load_flicker8k_captions() \n",
    "flicker_images = list(flicker_caption_map.keys())\n",
    "\n",
    "print('Total flicker images: ', len(flicker_images))\n",
    "print('Total flicker captions:', len(flicker_total_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training COCO images:  82783\n",
      "Validation COCO images:  40504\n",
      "Total COCO captions:  616767\n"
     ]
    }
   ],
   "source": [
    "coco_train_caption_map, coco_val_caption_map, coco_total_captions = load_coco_captions() \n",
    "\n",
    "coco_train_images = list(coco_train_caption_map.keys())\n",
    "coco_val_images = list(coco_val_caption_map.keys())\n",
    "\n",
    "print('Training COCO images: ', len(coco_train_images))\n",
    "print('Validation COCO images: ', len(coco_val_images))\n",
    "print('Total COCO captions: ', len(coco_total_captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = InceptionResNetV2(weights= 'imagenet', include_top= False, pooling = 'avg', input_shape=(224,224,3))\n",
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 10s 34ms/step\n",
      "32/32 [==============================] - 1s 37ms/step\n",
      "32/32 [==============================] - 2s 40ms/step\n",
      "32/32 [==============================] - 1s 40ms/step\n",
      "32/32 [==============================] - 1s 38ms/step\n",
      "32/32 [==============================] - 1s 32ms/step\n",
      "32/32 [==============================] - 1s 29ms/step\n",
      "29/29 [==============================] - 4s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from Flicker8K images and writing to file \n",
    "flicker_feature_map = batch_extract_features(flicker_images, 'datasets/flicker8k/Flicker8k_images', encoder)\n",
    "\n",
    "with open(FLICKER + 'avg_feature_map.pkl', 'wb') as file: \n",
    "    dump(flicker_feature_map, file)\n",
    "del flicker_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 77ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 66ms/step\n",
      "32/32 [==============================] - 2s 61ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 53ms/step\n",
      "32/32 [==============================] - 2s 59ms/step\n",
      "32/32 [==============================] - 2s 52ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 57ms/step\n",
      "32/32 [==============================] - 2s 59ms/step\n",
      "32/32 [==============================] - 1s 45ms/step\n",
      "32/32 [==============================] - 2s 56ms/step\n",
      "32/32 [==============================] - 2s 59ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 2s 58ms/step\n",
      "32/32 [==============================] - 2s 57ms/step\n",
      "32/32 [==============================] - 2s 53ms/step\n",
      "32/32 [==============================] - 2s 53ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 57ms/step\n",
      "32/32 [==============================] - 2s 58ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 62ms/step\n",
      "32/32 [==============================] - 2s 58ms/step\n",
      "32/32 [==============================] - 2s 56ms/step\n",
      "32/32 [==============================] - 2s 53ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 1s 42ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 1s 45ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 1s 43ms/step\n",
      "32/32 [==============================] - 1s 43ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 1s 43ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 1s 43ms/step\n",
      "32/32 [==============================] - 1s 43ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 1s 43ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 1s 43ms/step\n",
      "32/32 [==============================] - 1s 45ms/step\n",
      "32/32 [==============================] - 1s 43ms/step\n",
      "32/32 [==============================] - 1s 30ms/step\n",
      "32/32 [==============================] - 1s 29ms/step\n",
      "27/27 [==============================] - 1s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from COCO training images and writing to file \n",
    "coco_train_feature_map = batch_extract_features(coco_train_images, 'datasets/coco/train2014/', encoder)\n",
    "\n",
    "with open(COCO + 'train_avg_feature_map.pkl', 'wb') as file: \n",
    "    dump(coco_train_feature_map, file)\n",
    "    \n",
    "del coco_train_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 80ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 1s 45ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 55ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 1s 45ms/step\n",
      "32/32 [==============================] - 1s 45ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 2s 46ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 44ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 1s 41ms/step\n",
      "32/32 [==============================] - 1s 41ms/step\n",
      "32/32 [==============================] - 1s 44ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 1s 42ms/step\n",
      "32/32 [==============================] - 1s 35ms/step\n",
      "32/32 [==============================] - 1s 28ms/step\n",
      "32/32 [==============================] - 1s 28ms/step\n",
      "18/18 [==============================] - 1s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from COCO validation images and writing to file \n",
    "coco_val_feature_map = batch_extract_features(coco_val_images, 'datasets/coco/val2014/', encoder)\n",
    "\n",
    "with open(COCO + 'val_avg_feature_map.pkl', 'wb') as file: \n",
    "    dump(coco_val_feature_map, file)\n",
    "    \n",
    "del coco_val_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "\n",
    "encoder_2 = InceptionResNetV2(weights= 'imagenet', include_top= False, input_shape=(224,224,3))\n",
    "encoder_2.trainable = False\n",
    "encoder_2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 9s 39ms/step\n",
      "32/32 [==============================] - 1s 42ms/step\n",
      "32/32 [==============================] - 2s 43ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 1s 45ms/step\n",
      "32/32 [==============================] - 1s 35ms/step\n",
      "32/32 [==============================] - 1s 37ms/step\n",
      "29/29 [==============================] - 3s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from Flicker8K images and writing to file \n",
    "flicker_feature_map = batch_extract_features(flicker_images, 'datasets/flicker8k/Flicker8k_images', encoder_2)\n",
    "\n",
    "with open(FLICKER + 'feature_map.pkl', 'wb') as file: \n",
    "    dump(flicker_feature_map, file)\n",
    "del flicker_feature_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 56ms/step\n",
      "32/32 [==============================] - 2s 65ms/step\n",
      "32/32 [==============================] - 2s 64ms/step\n",
      "32/32 [==============================] - 2s 53ms/step\n",
      "32/32 [==============================] - 2s 56ms/step\n",
      "32/32 [==============================] - 2s 55ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 52ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 52ms/step\n",
      "32/32 [==============================] - 2s 58ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 5s 42ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 53ms/step\n",
      "32/32 [==============================] - 2s 58ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 55ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 55ms/step\n",
      "32/32 [==============================] - 2s 52ms/step\n",
      "32/32 [==============================] - 2s 56ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 52ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 52ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 52ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 55ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 52ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 54ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 1s 38ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 1s 37ms/step\n",
      "32/32 [==============================] - 1s 38ms/step\n",
      "27/27 [==============================] - 1s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from COCO training images and writing to file \n",
    "coco_train_feature_map = batch_extract_features(coco_train_images, 'datasets/coco/train2014/', encoder_2)\n",
    "\n",
    "with open(COCO + 'train_feature_map.pkl', 'wb') as file: \n",
    "    dump(coco_train_feature_map, file)\n",
    "    \n",
    "del coco_train_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 66ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "32/32 [==============================] - 2s 53ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 55ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 45ms/step\n",
      "32/32 [==============================] - 2s 49ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 57ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 58ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 2s 56ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 59ms/step\n",
      "32/32 [==============================] - 2s 59ms/step\n",
      "32/32 [==============================] - 2s 65ms/step\n",
      "32/32 [==============================] - 2s 47ms/step\n",
      "32/32 [==============================] - 2s 50ms/step\n",
      "32/32 [==============================] - 2s 51ms/step\n",
      "32/32 [==============================] - 1s 41ms/step\n",
      "32/32 [==============================] - 1s 36ms/step\n",
      "32/32 [==============================] - 1s 35ms/step\n",
      "18/18 [==============================] - 1s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from COCO validation images and writing to file \n",
    "coco_val_feature_map = batch_extract_features(coco_val_images, 'datasets/coco/val2014/', encoder_2)\n",
    "\n",
    "with open(COCO + 'val_feature_map.pkl', 'wb') as file: \n",
    "    dump(coco_val_feature_map, file)\n",
    "    \n",
    "del coco_val_feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    output_mode='int',  \n",
    "    output_sequence_length=SEQ_LENGTH + 1,  \n",
    "    standardize=custom_standardization,  \n",
    ")\n",
    "\n",
    "total_captions = flicker_total_captions + coco_total_captions\n",
    "\n",
    "captions_dataset = Dataset.from_tensor_slices(total_captions)\n",
    "captions_dataset = captions_dataset.batch(2048).prefetch(AUTOTUNE)\n",
    "\n",
    "text_vectorizer.adapt(captions_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  4096\n",
      "Found 400000 word vectors\n",
      "Converted 4047 words (49 misses)\n"
     ]
    }
   ],
   "source": [
    "vocab = text_vectorizer.get_vocabulary()\n",
    "\n",
    "with open('preprocessed_data/vocab.pkl', 'wb') as file: \n",
    "    dump(vocab, file)\n",
    "    \n",
    "print('Vocab size: ', len(vocab))\n",
    "\n",
    "word_to_idx, idx_to_word = create_vocab_mappings(vocab)\n",
    "\n",
    "embedding_matrix = create_embedding_matrix(EMBED_DIM, len(vocab), word_to_idx)\n",
    "\n",
    "with open('preprocessed_data/embedding_matrix.pkl', 'wb') as file: \n",
    "    dump(embedding_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Assuming vectorized_caption_map is your data\n",
    "# First, let's create a function to extract and prepare the data\n",
    "\n",
    "def analyze_vectors(vectorized_caption_map):\n",
    "    # Stack all vectors into a single array\n",
    "    all_vectors = np.vstack(list(vectorized_caption_map.values()))\n",
    "    return all_vectors\n",
    "\n",
    "def plot_vector_analysis(vectorized_caption_map):\n",
    "    all_vectors = analyze_vectors(vectorized_caption_map)\n",
    "    \n",
    "    # Create a figure with multiple subplots\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Vector Magnitude Distribution\n",
    "    plt.subplot(2, 2, 1)\n",
    "    magnitudes = np.linalg.norm(all_vectors, axis=1)\n",
    "    sns.histplot(magnitudes)\n",
    "    plt.title('Distribution of Vector Magnitudes')\n",
    "    plt.xlabel('Magnitude')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # 2. Dimension-wise Statistics\n",
    "    plt.subplot(2, 2, 2)\n",
    "    mean_values = np.mean(all_vectors, axis=0)\n",
    "    plt.plot(mean_values)\n",
    "    plt.title('Mean Values Across Dimensions')\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.ylabel('Mean Value')\n",
    "    \n",
    "    # 3. Dimension-wise Variance\n",
    "    plt.subplot(2, 2, 3)\n",
    "    variances = np.var(all_vectors, axis=0)\n",
    "    plt.bar(range(len(variances)), variances)\n",
    "    plt.title('Variance Across Dimensions')\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.ylabel('Variance')\n",
    "    \n",
    "    # 4. PCA Visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(all_vectors)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n",
    "    plt.title('PCA Visualization (2D)')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive visualizations with Plotly\n",
    "def create_interactive_plots(vectorized_caption_map):\n",
    "    all_vectors = analyze_vectors(vectorized_caption_map)\n",
    "    \n",
    "    # t-SNE visualization\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(all_vectors)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tsne_results[:, 0],\n",
    "        y=tsne_results[:, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=np.linalg.norm(all_vectors, axis=1),\n",
    "            colorscale='Viridis',\n",
    "            showscale=True\n",
    "        ),\n",
    "        text=[f\"Vector {i}\" for i in range(len(all_vectors))]\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='t-SNE Visualization of Vectors',\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Usage example:\n",
    "# plot_vector_analysis(your_vectorized_caption_map)\n",
    "# create_interactive_plots(your_vectorized_caption_map)\n",
    "\n",
    "# Heatmap of vector correlations\n",
    "def plot_vector_correlations(vectorized_caption_map):\n",
    "    all_vectors = analyze_vectors(vectorized_caption_map)\n",
    "    corr_matrix = np.corrcoef(all_vectors.T)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', center=0)\n",
    "    plt.title('Vector Dimension Correlations')\n",
    "    plt.show()\n",
    "\n",
    "# Plot sequence lengths if available\n",
    "def plot_sequence_lengths(caption_map):\n",
    "    lengths = [len(caption) for captions in caption_map.values() for caption in captions]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(lengths, bins=30)\n",
    "    plt.title('Distribution of Caption Lengths')\n",
    "    plt.xlabel('Length')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original caption:  A man sits on a step with two duffel bags and a plastic bag by his sides .\n",
      "Vectorized caption:  [   3    2   12   98    5    2 1804    9   15    1  642   10    2  493\n",
      "  392   51   39  922    4    0    0]\n",
      "Decoded caption:  ['a', 'man', 'sits', 'on', 'a', 'step', 'with', 'two', '[UNK]', 'bags', 'and', 'a', 'plastic', 'bag', 'by', 'his', 'sides']\n"
     ]
    }
   ],
   "source": [
    "test_image = choice(flicker_images)\n",
    "test_caption = flicker_caption_map[test_image][0]\n",
    "print('Original caption: ', test_caption)\n",
    "\n",
    "flicker_caption_map = vectorize_captions(flicker_caption_map, text_vectorizer)\n",
    "\n",
    "test_caption = flicker_caption_map[test_image][0]\n",
    "print('Vectorized caption: ', test_caption)\n",
    "\n",
    "print('Decoded caption: ', decode_caption(test_caption, idx_to_word))\n",
    "\n",
    "with open(FLICKER + 'caption_map.pkl', 'wb') as file: \n",
    "    dump(flicker_caption_map, file)\n",
    "\n",
    "# # Basic static visualizations\n",
    "# plot_vector_analysis(flicker_caption_map)\n",
    "\n",
    "del flicker_caption_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic static visualizations\n",
    "# plot_vector_analysis(flicker_caption_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished vectorizing coco training captions\n",
      "Completed writting vectorized training captions to file\n",
      "Finished vectorizing coco validation captions\n",
      "Completed writting vectorized validation captions to file\n"
     ]
    }
   ],
   "source": [
    "coco_train_caption_map = vectorize_captions(coco_train_caption_map, text_vectorizer) \n",
    "\n",
    "print('Finished vectorizing coco training captions')\n",
    "\n",
    "with open(COCO + 'train_caption_map.pkl', 'wb') as file: \n",
    "    dump(coco_train_caption_map, file)\n",
    "\n",
    "del coco_train_caption_map\n",
    "\n",
    "print('Completed writting vectorized training captions to file')\n",
    "    \n",
    "coco_val_caption_map = vectorize_captions(coco_val_caption_map, text_vectorizer)\n",
    "\n",
    "print('Finished vectorizing coco validation captions')\n",
    "\n",
    "with open(COCO + 'val_caption_map.pkl', 'wb') as file: \n",
    "    dump(coco_val_caption_map, file)\n",
    "    \n",
    "del coco_val_caption_map\n",
    "\n",
    "print('Completed writting vectorized validation captions to file')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
